{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python UI for make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "objc[1951]: Class CaptureDelegate is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17bada520) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x306f4c860). One of the two will be used. Which one is undefined.\n",
      "objc[1951]: Class CVWindow is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17bada570) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x3031f0a68). One of the two will be used. Which one is undefined.\n",
      "objc[1951]: Class CVView is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17bada598) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x3031f0a90). One of the two will be used. Which one is undefined.\n",
      "objc[1951]: Class CVSlider is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17bada5c0) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x3031f0ab8). One of the two will be used. Which one is undefined.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-12-24 14:40:52.401 python[1951:18268] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-12-24 14:40:55.412 python[1951:18268] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-24 14:40:55.412 python[1951:18268] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved parameters to output_from_capture/parameters_004.csv\n",
      "\n",
      "Saved parameters:\n",
      "timestamp: 2024-12-24 14:41:15\n",
      "file_number: 004\n",
      "screen_resolution_width: 1728\n",
      "screen_resolution_height: 1117\n",
      "webcam_resolution_width: 1280\n",
      "webcam_resolution_height: 720\n",
      "preview_width: 640\n",
      "preview_height: 360\n",
      "canvas_width: 1708\n",
      "canvas_height: 920\n",
      "gaze_direction: Looking left\n",
      "posture: Looking Down\n",
      "dot_position_x: 321\n",
      "dot_position_y: 733\n",
      "distance_cm: 56.0\n",
      "face_size_width: 251\n",
      "face_size_hight: 338\n",
      "face_min_position_x: 504\n",
      "face_min_position_y: 230\n",
      "face_max_position_x: 755\n",
      "face_max_position_y: 568\n",
      "face_center_position_x: 629\n",
      "face_center_position_y: 399\n",
      "left_eye_pupil_x: 577\n",
      "left_eye_pupil_y: 351\n",
      "right_eye_pupil_x: 692\n",
      "right_eye_pupil_y: 353\n",
      "right_eye_bbox_min_x: 653\n",
      "right_eye_bbox_min_y: 328\n",
      "right_eye_bbox_max_x: 732\n",
      "right_eye_bbox_max_y: 378\n",
      "left_eye_bbox_min_x: 531\n",
      "left_eye_bbox_min_y: 325\n",
      "left_eye_bbox_max_x: 613\n",
      "left_eye_bbox_max_y: 376\n",
      "Images saved successfully:\n",
      "- Webcam: output_from_capture/webcam_004.jpg\n",
      "- Canvas: output_from_capture/screen_004.jpg\n",
      "Successfully saved parameters to output_from_capture/parameters_005.csv\n",
      "\n",
      "Saved parameters:\n",
      "timestamp: 2024-12-24 14:41:25\n",
      "file_number: 005\n",
      "screen_resolution_width: 1728\n",
      "screen_resolution_height: 1117\n",
      "webcam_resolution_width: 1280\n",
      "webcam_resolution_height: 720\n",
      "preview_width: 640\n",
      "preview_height: 360\n",
      "canvas_width: 1708\n",
      "canvas_height: 920\n",
      "gaze_direction: Looking center\n",
      "posture: Looking Down\n",
      "dot_position_x: 1285\n",
      "dot_position_y: 702\n",
      "distance_cm: 55.55555555555556\n",
      "face_size_width: 251\n",
      "face_size_hight: 338\n",
      "face_min_position_x: 504\n",
      "face_min_position_y: 230\n",
      "face_max_position_x: 755\n",
      "face_max_position_y: 568\n",
      "face_center_position_x: 629\n",
      "face_center_position_y: 399\n",
      "left_eye_pupil_x: 564\n",
      "left_eye_pupil_y: 351\n",
      "right_eye_pupil_x: 677\n",
      "right_eye_pupil_y: 352\n",
      "right_eye_bbox_min_x: 653\n",
      "right_eye_bbox_min_y: 328\n",
      "right_eye_bbox_max_x: 732\n",
      "right_eye_bbox_max_y: 378\n",
      "left_eye_bbox_min_x: 531\n",
      "left_eye_bbox_min_y: 325\n",
      "left_eye_bbox_max_x: 613\n",
      "left_eye_bbox_max_y: 376\n",
      "Images saved successfully:\n",
      "- Webcam: output_from_capture/webcam_005.jpg\n",
      "- Canvas: output_from_capture/screen_005.jpg\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyautogui\n",
    "from ultralytics import YOLO\n",
    "from huggingface_hub import hf_hub_download\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gaze_tracking import GazeTracking\n",
    "import csv\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "import screeninfo\n",
    "\n",
    "\n",
    "class YoloDistanceApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"YOLO Face Detection with Distance Measurement\")\n",
    "\n",
    "        # Get screen resolution before initializing other components\n",
    "        screen_size = pyautogui.size()\n",
    "        self.screen_width = screen_size[0]\n",
    "        self.screen_height = screen_size[1]\n",
    "\n",
    "        # Initialize trackers and detectors\n",
    "        self.gaze = GazeTracking()\n",
    "        self.fm = FaceMeshDetector(maxFaces=1)\n",
    "\n",
    "        # Define eye landmark points\n",
    "        self.rightEye = {\n",
    "            'upper': [463, 414, 286, 258, 257, 259, 260],\n",
    "            'lower': [467, 359, 255, 339, 254, 253, 252, 256, 341]\n",
    "        }\n",
    "\n",
    "        self.leftEye = {\n",
    "            'upper': [130, 247, 30, 29, 27, 28, 56],\n",
    "            'lower': [190, 243, 112, 26, 22, 23, 24, 110, 25]\n",
    "        }\n",
    "\n",
    "        self.output_dir = \"output_from_capture\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        self.file_counter = 1\n",
    "        self.update_next_available_number()\n",
    "\n",
    "        # Initialize YOLO model\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=\"arnabdhar/YOLOv8-Face-Detection\",\n",
    "            filename=\"model.pt\"\n",
    "        )\n",
    "        self.model_face = YOLO(model_path)\n",
    "        self.model_face.conf = 0.25\n",
    "        self.model_face.iou = 0.45\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.current_parameters = {\n",
    "            'left_eye_position': None,\n",
    "            'right_eye_position': None,\n",
    "            'gaze_direction': None,\n",
    "            'distance': None,\n",
    "            'posture': None,\n",
    "            'dot_position_x': None,\n",
    "            'dot_position_y': None,\n",
    "            'webcam_resolution_width': None,\n",
    "            'webcam_resolution_height': None,\n",
    "            'screen_resolution_width': self.screen_width,\n",
    "            'screen_resolution_height': self.screen_height,\n",
    "            'preview_width': None,\n",
    "            'preview_height': None,\n",
    "            'canvas_width': None,\n",
    "            'canvas_height': None,\n",
    "            'face_size_width': None,\n",
    "            'face_size_hight': None,\n",
    "            'face_min_position': None,\n",
    "            'face_max_position': None,\n",
    "            'face_center_position': None,\n",
    "            'right_eye_bbox': None,\n",
    "            'left_eye_bbox': None\n",
    "        }\n",
    "\n",
    "        self.original_canvas_width = 1728\n",
    "        self.original_canvas_height = 1117\n",
    "        self.switch_parameterOnScreen = False\n",
    "        self.position_left_label = None\n",
    "        self.position_right_label = None\n",
    "        self.gaze_label = None\n",
    "        self.canvas_normal_state = True\n",
    "        self.controls_visible = True\n",
    "        self.focal_length = 1000\n",
    "        self.FACE_WIDTH_CM = 14\n",
    "        self.preview_active = False\n",
    "        self.webcam_width = 640\n",
    "        self.webcam_height = 360\n",
    "        self.current_dot = None\n",
    "        self.capture_counter = 0\n",
    "\n",
    "        self.setup_gui()\n",
    "\n",
    "        # Initialize webcam\n",
    "        self.cap = cv2.VideoCapture(1)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "        # Start preview update\n",
    "        self.update_preview()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        # Top bar with dark background for better visibility\n",
    "        self.top_bar = tk.Frame(self.root, bg='#2C3E50')\n",
    "        self.top_bar.pack(fill='x')\n",
    "\n",
    "        # Controls frame\n",
    "        self.controls_frame = tk.Frame(self.top_bar, bg='#2C3E50')\n",
    "        self.controls_frame.pack(fill='x', padx=5, pady=5)\n",
    "\n",
    "        # Create a single hideable container for all elements\n",
    "        self.all_hideable_content = tk.Frame(self.controls_frame, bg='#2C3E50')\n",
    "        self.all_hideable_content.pack(side=tk.LEFT, fill='x', expand=True)\n",
    "\n",
    "        # Buttons section with input\n",
    "        self.buttons_frame = tk.Frame(self.all_hideable_content, bg='#2C3E50')\n",
    "        self.buttons_frame.pack(fill='x', padx=5)\n",
    "\n",
    "        # Random times input\n",
    "        self.random_times_frame = tk.Frame(self.buttons_frame, bg='#2C3E50')\n",
    "        self.random_times_frame.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.random_times_label = tk.Label(\n",
    "            self.random_times_frame,\n",
    "            text=\"Times:\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.random_times_label.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        self.random_times_entry = ttk.Entry(\n",
    "            self.random_times_frame,\n",
    "            width=5\n",
    "        )\n",
    "        self.random_times_entry.insert(0, \"1\")\n",
    "        self.random_times_entry.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        # Delay input\n",
    "        self.delay_frame = tk.Frame(self.buttons_frame, bg='#2C3E50')\n",
    "        self.delay_frame.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.delay_label = tk.Label(\n",
    "            self.delay_frame,\n",
    "            text=\"Delay(s):\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.delay_label.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        self.delay_entry = ttk.Entry(\n",
    "            self.delay_frame,\n",
    "            width=5\n",
    "        )\n",
    "        self.delay_entry.insert(0, \"3\")\n",
    "        self.delay_entry.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        # Screen selection\n",
    "        self.selected_screen = tk.StringVar()\n",
    "        self.screens = screeninfo.get_monitors()\n",
    "\n",
    "        self.screen_selection_frame = tk.Frame(\n",
    "            self.buttons_frame, bg='#2C3E50')\n",
    "        self.screen_selection_frame.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.screen_label = tk.Label(\n",
    "            self.screen_selection_frame,\n",
    "            text=\"Screen:\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.screen_label.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        self.screen_dropdown = ttk.Combobox(\n",
    "            self.screen_selection_frame,\n",
    "            textvariable=self.selected_screen,\n",
    "            width=15\n",
    "        )\n",
    "        self.screen_dropdown['values'] = [f\"Screen {i+1}: {s.width}x{s.height}\"\n",
    "                                          for i, s in enumerate(self.screens)]\n",
    "        if self.screen_dropdown['values']:\n",
    "            self.screen_dropdown.set(self.screen_dropdown['values'][0])\n",
    "        self.screen_dropdown.pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        # Action Buttons\n",
    "        self.set_random_button = ttk.Button(\n",
    "            self.buttons_frame,\n",
    "            text=\"Set Random\",\n",
    "            command=self.set_random_parameters\n",
    "        )\n",
    "        self.set_random_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.random_button = ttk.Button(\n",
    "            self.buttons_frame,\n",
    "            text=\"Random Dot\",\n",
    "            command=self.draw_random_dot_and_capture\n",
    "        )\n",
    "        self.random_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.clear_button = ttk.Button(\n",
    "            self.buttons_frame,\n",
    "            text=\"Clear All\",\n",
    "            command=self.clear_all\n",
    "        )\n",
    "        self.clear_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Show/Hide Preview switch\n",
    "        self.preview_var = tk.BooleanVar(value=False)\n",
    "        self.preview_switch = ttk.Checkbutton(\n",
    "            self.buttons_frame,\n",
    "            text=\"Show Preview\",\n",
    "            variable=self.preview_var,\n",
    "            command=self.toggle_preview\n",
    "        )\n",
    "        self.preview_switch.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Parameters toggle switch\n",
    "        self.parameter_var = tk.BooleanVar(value=False)\n",
    "        self.parameter_switch = ttk.Checkbutton(\n",
    "            self.buttons_frame,\n",
    "            text=\"Show Parameters\",\n",
    "            variable=self.parameter_var,\n",
    "            command=self.toggle_parameters\n",
    "        )\n",
    "        self.parameter_switch.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Status section (in the same hideable container)\n",
    "        self.status_frame = tk.Frame(self.all_hideable_content, bg='#2C3E50')\n",
    "        self.status_frame.pack(fill='x', padx=5, pady=5)\n",
    "\n",
    "        # Status Row 1\n",
    "        self.status_row1 = tk.Frame(self.status_frame, bg='#2C3E50')\n",
    "        self.status_row1.pack(fill='x', pady=2)\n",
    "\n",
    "        # self.countdown_label = tk.Label(\n",
    "        #     self.status_row1,\n",
    "        #     text=\"\",\n",
    "        #     font=('Arial', 26, 'bold'),\n",
    "        #     bg='#2C3E50',\n",
    "        #     fg='white'\n",
    "        # )\n",
    "        # self.countdown_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Top bar with dark background for better visibility\n",
    "        self.top_bar = tk.Frame(self.root, bg='#2C3E50')\n",
    "        self.top_bar.pack(fill='x')\n",
    "\n",
    "        self.distance_label = tk.Label(\n",
    "            self.status_row1,\n",
    "            text=\"Distance: -- cm\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.distance_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.posture_label = tk.Label(\n",
    "            self.status_row1,\n",
    "            text=\"Posture: --\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.posture_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.countdown_label = tk.Label(\n",
    "            self.status_row1,\n",
    "            text=\"\",\n",
    "            font=('Arial', 36, 'bold'),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.countdown_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Status Row 2\n",
    "        self.status_row2 = tk.Frame(self.status_frame, bg='#2C3E50')\n",
    "        self.status_row2.pack(fill='x', pady=2)\n",
    "\n",
    "        self.position_left_label = tk.Label(\n",
    "            self.status_row2,\n",
    "            text=\"left: (--, --)\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.position_left_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.position_right_label = tk.Label(\n",
    "            self.status_row2,\n",
    "            text=\"right: (--, --)\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.position_right_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.gaze_label = tk.Label(\n",
    "            self.status_row2,\n",
    "            text=\"Gaze: --\",\n",
    "            font=('Arial', 12),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.gaze_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.signal_label = tk.Label(\n",
    "            self.status_row1,\n",
    "            text=\"\",\n",
    "            font=('Arial', 36, 'bold'),\n",
    "            bg='#2C3E50',\n",
    "            fg='white'\n",
    "        )\n",
    "        self.signal_label.pack(side=tk.RIGHT, padx=5)\n",
    "\n",
    "        # Toggle controls button (outside hideable container)\n",
    "        self.toggle_controls_btn = ttk.Button(\n",
    "            self.controls_frame,\n",
    "            text=\"≡\",\n",
    "            width=3,\n",
    "            command=self.toggle_controls\n",
    "        )\n",
    "        self.toggle_controls_btn.pack(side=tk.RIGHT, padx=5)\n",
    "\n",
    "        # Main container with padding\n",
    "        self.main_container = tk.Frame(self.root)\n",
    "        self.main_container.pack(expand=True, fill='both', padx=10, pady=10)\n",
    "\n",
    "        # Canvas section\n",
    "        self.canvas_frame = tk.Frame(self.main_container)\n",
    "        self.canvas_frame.pack(expand=True, fill='both')\n",
    "\n",
    "        self.canvas = tk.Canvas(\n",
    "            self.canvas_frame,\n",
    "            width=self.original_canvas_width,\n",
    "            height=self.original_canvas_height,\n",
    "            bg='white'\n",
    "        )\n",
    "        self.canvas.pack(expand=True, fill='both')\n",
    "\n",
    "        # label oin the reg dot\n",
    "        self.dot_countdown_label = tk.Label(\n",
    "            self.canvas,\n",
    "            text=\"\",\n",
    "            font=('Arial', 32, 'bold'),\n",
    "            fg='red',\n",
    "            bg='white'\n",
    "        )\n",
    "        # Preview frame\n",
    "        self.preview_frame = tk.Frame(self.main_container)\n",
    "\n",
    "        # Preview labels\n",
    "        self.webcam_label = tk.Label(self.preview_frame)\n",
    "        self.screen_label = tk.Label(self.preview_frame)\n",
    "\n",
    "    def toggle_preview(self):\n",
    "        \"\"\"Toggle visibility of the preview panel\"\"\"\n",
    "        if self.preview_var.get():\n",
    "            # Show preview\n",
    "            # self.switch_parameterOnScreen = True\n",
    "            self.canvas_normal_state = False\n",
    "            self.preview_frame.place(\n",
    "                in_=self.canvas_frame,  # Place relative to canvas frame\n",
    "                relx=0.5,              # Center horizontally\n",
    "                rely=0.5,              # Center vertically\n",
    "                anchor='center'        # Center anchor point\n",
    "            )\n",
    "            # self.preview_frame.place(\n",
    "            #     relx=1.0,  # Right align\n",
    "            #     rely=0,    # Top align\n",
    "            #     anchor='ne',  # North-east anchor\n",
    "            #     y=10,      # Small padding from top\n",
    "            #     x=-10      # Small padding from right\n",
    "            # )\n",
    "            self.webcam_label.pack(side=tk.LEFT, padx=5)\n",
    "            self.screen_label.pack(side=tk.LEFT, padx=5)\n",
    "        else:\n",
    "            # Hide preview\n",
    "            self.parameter_var.set(False)\n",
    "            self.switch_parameterOnScreen = False\n",
    "\n",
    "            self.canvas_normal_state = True\n",
    "            self.preview_frame.place_forget()\n",
    "            self.webcam_label.pack_forget()\n",
    "            self.screen_label.pack_forget()\n",
    "\n",
    "    def save_capture(self, frame, screen, timestamp):\n",
    "        cv2.imwrite(\n",
    "            f\"{self.output_dir}/webcam_{timestamp}.jpg\",\n",
    "            cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        )\n",
    "        screen.save(f\"{self.output_dir}/screen_{timestamp}.jpg\")\n",
    "        print(f\"Images saved with timestamp: {timestamp}\")\n",
    "\n",
    "    def toggle_controls(self, force_hide=False):\n",
    "        if self.controls_visible or force_hide:\n",
    "            self.all_hideable_content.pack_forget()\n",
    "            self.toggle_controls_btn.configure(text=\"≡\")\n",
    "            self.controls_visible = False\n",
    "        else:\n",
    "            self.all_hideable_content.pack(side=tk.LEFT, fill='x', expand=True)\n",
    "            self.toggle_controls_btn.configure(text=\"×\")\n",
    "            self.controls_visible = True\n",
    "\n",
    "    def get_eye_bbox(self, landmarks, eye_points):\n",
    "        point_array = np.array([landmarks[idx]\n",
    "                               for group in eye_points.values() for idx in group])\n",
    "        x_min = int(np.min(point_array[:, 0])) - 10\n",
    "        x_max = int(np.max(point_array[:, 0])) + 10\n",
    "        y_min = int(np.min(point_array[:, 1])) - 10\n",
    "        y_max = int(np.max(point_array[:, 1])) + 10\n",
    "        return (x_min, y_min), (x_max, y_max)\n",
    "\n",
    "    def measure_distance(self, face_width_pixels):\n",
    "        return (self.FACE_WIDTH_CM * self.focal_length) / face_width_pixels\n",
    "\n",
    "    def update_y_position(self, y_position):\n",
    "        y_position += 54\n",
    "        return y_position\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        # Update gaze tracking\n",
    "        self.gaze.refresh(frame)\n",
    "\n",
    "        # YOLO face detection\n",
    "        results = self.model_face.predict(\n",
    "            frame,\n",
    "            conf=0.25,\n",
    "            iou=0.45,\n",
    "            max_det=1,\n",
    "            classes=[0],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Face mesh detection\n",
    "        _, faces = self.fm.findFaceMesh(frame, draw=0)\n",
    "\n",
    "        # Get clean frame for non-parameter view\n",
    "        clean_frame = frame.copy()\n",
    "\n",
    "        # Process gaze direction\n",
    "        gaze_text = \"Gaze not detected\"\n",
    "        if self.gaze.is_right():\n",
    "            gaze_text = \"Looking right\"\n",
    "        elif self.gaze.is_left():\n",
    "            gaze_text = \"Looking left\"\n",
    "        elif self.gaze.is_center():\n",
    "            gaze_text = \"Looking center\"\n",
    "\n",
    "        # Update GUI labels\n",
    "        self.gaze_label.config(text=f\"Gaze: {gaze_text}\")\n",
    "\n",
    "        # Get and update pupil positions\n",
    "        left_pupil = self.gaze.pupil_left_coords()\n",
    "        right_pupil = self.gaze.pupil_right_coords()\n",
    "\n",
    "        self.position_left_label.config(text=f\"left: {left_pupil}\")\n",
    "        self.position_right_label.config(text=f\"right: {right_pupil}\")\n",
    "\n",
    "        # Update parameters\n",
    "        self.current_parameters['gaze_direction'] = gaze_text\n",
    "        self.current_parameters['left_eye_position'] = str(left_pupil)\n",
    "        self.current_parameters['right_eye_position'] = str(right_pupil)\n",
    "\n",
    "        # Process face detection results\n",
    "        if len(results[0].boxes) > 0:\n",
    "            box = results[0].boxes[0]\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            face_width = x2 - x1\n",
    "            face_height = y2 - y1\n",
    "            face_center_x = (x1 + x2) // 2\n",
    "            face_center_y = (y1 + y2) // 2\n",
    "\n",
    "            # Calculate distance without smoothing\n",
    "            distance = self.measure_distance(face_width)\n",
    "\n",
    "            # Update distance in parameters and GUI\n",
    "            self.current_parameters['distance'] = f\"{distance}\"\n",
    "            self.distance_label.config(text=f\"Distance: {distance:.1f} cm\")\n",
    "\n",
    "            if self.switch_parameterOnScreen:\n",
    "                frame = self.gaze.annotated_frame()\n",
    "                y_position = 40\n",
    "\n",
    "                # YOLO detection confidence\n",
    "                cv2.putText(frame, f\"YOLO Confidence: {float(box.conf[0]):.3f}\",\n",
    "                            (10, y_position),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 255, 0), 3)\n",
    "                y_position = self.update_y_position(y_position)\n",
    "\n",
    "                # Face size\n",
    "                cv2.putText(frame, f\"Face Size: {round(face_width, 2)} x {round(face_height, 2)}\",\n",
    "                            (10, y_position),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                self.current_parameters['face_size_width'] = round(\n",
    "                    face_width, 2)\n",
    "                self.current_parameters['face_size_hight'] = round(\n",
    "                    face_height, 2)\n",
    "                y_position = self.update_y_position(y_position)\n",
    "\n",
    "                # Face box position\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                face_min_position = (x1, y1)\n",
    "                face_max_position = (x2, y2)\n",
    "                cv2.putText(frame, f\"Face -> min: {face_min_position}, max:{face_max_position}\", (10, y_position),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                self.current_parameters['face_min_position'] = face_min_position\n",
    "                self.current_parameters['face_max_position'] = face_max_position\n",
    "                y_position = self.update_y_position(y_position)\n",
    "\n",
    "                # Face center\n",
    "                position_center_face = (face_center_x, face_center_y)\n",
    "                cv2.circle(frame, position_center_face,\n",
    "                           3, (0, 0, 255), -1)\n",
    "                cv2.putText(frame, f\"Face Center: {position_center_face}\",\n",
    "                            (10, y_position),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                self.current_parameters['face_center_position'] = position_center_face\n",
    "                y_position = self.update_y_position(y_position)\n",
    "\n",
    "                # Pupil positions\n",
    "                if right_pupil:\n",
    "                    cv2.putText(frame, f\"Right Pupil: {right_pupil}\",\n",
    "                                (10, y_position),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                    y_position = self.update_y_position(y_position)\n",
    "                if left_pupil:\n",
    "                    cv2.putText(frame, f\"Left Pupil: {left_pupil}\",\n",
    "                                (10, y_position),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                    y_position = self.update_y_position(y_position)\n",
    "                # Process eye landmarks if face mesh is detected\n",
    "                if faces:\n",
    "                    face_landmarks = faces[0]\n",
    "                    for eye_name, eye_points in [(\"Right Eye\", self.rightEye), (\"Left Eye\", self.leftEye)]:\n",
    "                        (ex1, ey1), (ex2, ey2) = self.get_eye_bbox(\n",
    "                            face_landmarks, eye_points)\n",
    "                        cv2.rectangle(frame, (ex1, ey1),\n",
    "                                      (ex2, ey2), (255, 0, 0), 2)\n",
    "                        cv2.putText(frame, f\"{eye_name}-> min:({ex1},{ey1}), max:({ex2},{ey2})\", (10, y_position),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                        if eye_name == \"Right Eye\":\n",
    "                            self.current_parameters['right_eye_bbox'] = [\n",
    "                                ex1, ey1, ex2, ey2]\n",
    "                        else:\n",
    "                            self.current_parameters['left_eye_bbox'] = [\n",
    "                                ex1, ey1, ex2, ey2]\n",
    "                        y_position = self.update_y_position(y_position)\n",
    "\n",
    "                        # Draw eye landmarks\n",
    "                        for i in eye_points['upper']:\n",
    "                            cv2.circle(\n",
    "                                frame, face_landmarks[i], 2, (0, 255, 255), -1)\n",
    "                        for i in eye_points['lower']:\n",
    "                            cv2.circle(\n",
    "                                frame, face_landmarks[i], 2, (255, 255, 0), -1)\n",
    "\n",
    "                # Draw distance measurement\n",
    "                cv2.putText(frame, f\"Distance: {distance:.1f} cm\",\n",
    "                            (10, y_position),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "                y_position = self.update_y_position(y_position)\n",
    "\n",
    "                # Draw gaze direction\n",
    "                cv2.putText(frame, f\"Gaze: {gaze_text}\",\n",
    "                            (10, y_position),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "\n",
    "            # Calculate posture\n",
    "            aspect_ratio = face_width / face_height\n",
    "            posture = \"Forward\"\n",
    "            if aspect_ratio > 1.1:\n",
    "                posture = \"Turned Left/Right\"\n",
    "            elif aspect_ratio < 0.9:\n",
    "                if face_center_y < frame.shape[0] // 2:\n",
    "                    posture = \"Looking Up\"\n",
    "                else:\n",
    "                    posture = \"Looking Down\"\n",
    "\n",
    "            self.posture_label.config(text=f\"Posture: {posture}\")\n",
    "            self.current_parameters['posture'] = posture\n",
    "\n",
    "        return frame if self.switch_parameterOnScreen else clean_frame\n",
    "\n",
    "    def update_preview(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            # Update preview dimensions\n",
    "            self.current_parameters['webcam_resolution_width'] = int(\n",
    "                frame.shape[1])  # width is at index 1\n",
    "            self.current_parameters['webcam_resolution_height'] = int(\n",
    "                frame.shape[0])  # height is at index 0\n",
    "            self.current_parameters['preview_width'] = self.webcam_width\n",
    "            self.current_parameters['preview_height'] = self.webcam_height\n",
    "\n",
    "            frame_processed = self.process_frame(frame.copy())\n",
    "            frame_resized = cv2.resize(\n",
    "                frame_processed,\n",
    "                (self.webcam_width, self.webcam_height)\n",
    "            )\n",
    "            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "            photo = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))\n",
    "            self.webcam_label.configure(image=photo)\n",
    "            self.webcam_label.image = photo\n",
    "\n",
    "        self.root.after(10, self.update_preview)\n",
    "\n",
    "    def set_random_parameters(self):\n",
    "        \"\"\"Set random parameters for multiple captures\"\"\"\n",
    "        try:\n",
    "            num_times = int(self.random_times_entry.get())\n",
    "            if num_times <= 0:\n",
    "                print(\"Please enter a positive number\")\n",
    "                return\n",
    "\n",
    "            # Disable buttons during capture sequence\n",
    "            self.set_random_button.config(state=tk.DISABLED)\n",
    "            self.random_button.config(state=tk.DISABLED)\n",
    "\n",
    "            # Schedule multiple captures\n",
    "            self.schedule_multiple_captures(num_times)\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "\n",
    "    # Remove/delete this entire method:\n",
    "    def update_delay_label(self, *args):\n",
    "        value = int(self.delay_scale.get())\n",
    "        self.delay_value_label.config(text=f\"{value}s\")\n",
    "\n",
    "    # Modify schedule_multiple_captures to use the scale value\n",
    "    def schedule_multiple_captures(self, remaining_times):\n",
    "        if remaining_times > 0:\n",
    "            try:\n",
    "                self.signal_label.config(\n",
    "                    text=f\"{remaining_times} Processing.....\")\n",
    "                # Get delay from entry in milliseconds\n",
    "                delay_s = float(self.delay_entry.get())\n",
    "                if delay_s <= 0:\n",
    "                    print(\"Please enter a positive delay time\")\n",
    "                    return\n",
    "\n",
    "                delay_ms = int(delay_s * 1000)\n",
    "\n",
    "                def capture_with_delay():\n",
    "                    self.draw_random_dot_and_capture()\n",
    "                    # Schedule next capture after current one completes\n",
    "                    self.root.after(delay_ms,\n",
    "                                    lambda: self.schedule_multiple_captures(remaining_times - 1))\n",
    "\n",
    "                self.root.after(5000, capture_with_delay)\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid delay time\")\n",
    "                self.signal_label.config(text=f\"Error.....\")\n",
    "                self.set_random_button.config(state=tk.NORMAL)\n",
    "                self.random_button.config(state=tk.NORMAL)\n",
    "        else:\n",
    "            self.signal_label.config(text=f\"- Done -\")\n",
    "            self.root.after(1000, self.signal_label.config(text=f\"\"))\n",
    "            self.set_random_button.config(state=tk.NORMAL)\n",
    "            self.random_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def update_dot(self, random_position=False):\n",
    "        # Clear previous dots\n",
    "        if hasattr(self, 'dot_id'):\n",
    "            self.canvas.delete(self.dot_id)\n",
    "        if hasattr(self, 'current_dot'):\n",
    "            self.canvas.delete(self.current_dot)\n",
    "\n",
    "        # Generate new position if random is requested\n",
    "        if random_position:\n",
    "            self.dot_x = random.randint(1, self.canvas.winfo_width()-1)\n",
    "            self.dot_y = random.randint(1, self.canvas.winfo_height()-1)\n",
    "\n",
    "        # Update parameters\n",
    "        self.current_parameters['dot_position_x'] = self.dot_x\n",
    "        self.current_parameters['dot_position_y'] = self.dot_y\n",
    "\n",
    "        # Draw new dot\n",
    "        dot_radius = 5\n",
    "        self.dot_id = self.canvas.create_oval(\n",
    "            self.dot_x - dot_radius,\n",
    "            self.dot_y - dot_radius,\n",
    "            self.dot_x + dot_radius,\n",
    "            self.dot_y + dot_radius,\n",
    "            fill='red',\n",
    "            outline='red'\n",
    "        )\n",
    "        self.current_dot = self.dot_id  # Keep both references synchronized\n",
    "\n",
    "        # Update label position if it exists\n",
    "        if hasattr(self, 'dot_countdown_label'):\n",
    "            self.update_dot_label_position()\n",
    "\n",
    "    def draw_random_dot_and_capture(self):\n",
    "        # Hide any existing label\n",
    "        if hasattr(self, 'dot_countdown_label'):\n",
    "            self.dot_countdown_label.place_forget()\n",
    "        if self.current_dot:\n",
    "            self.canvas.delete(self.current_dot)\n",
    "            self.dot_countdown_label.place_forget()\n",
    "\n",
    "        self.capture_in_progress = True\n",
    "\n",
    "        # Draw new random dot\n",
    "        self.update_dot(random_position=True)\n",
    "\n",
    "        # Reset UI state\n",
    "        self.preview_var.set(False)\n",
    "        self.canvas_normal_state = True\n",
    "        self.preview_frame.place_forget()\n",
    "        self.webcam_label.pack_forget()\n",
    "        self.screen_label.pack_forget()\n",
    "        self.switch_parameterOnScreen = False\n",
    "        self.toggle_controls(force_hide=True)\n",
    "\n",
    "        # Start countdown\n",
    "        self.root.after(100, lambda: self.countdown(4))\n",
    "\n",
    "    def toggle_parameters(self):\n",
    "        \"\"\"Toggle visibility of the parameters on screen\"\"\"\n",
    "        self.switch_parameterOnScreen = self.parameter_var.get()\n",
    "\n",
    "    def save_parameters_to_csv(self, filename_base):\n",
    "        csv_path = os.path.join(\n",
    "            self.output_dir, f\"parameters_{filename_base}.csv\")\n",
    "\n",
    "        self.current_parameters['canvas_width'] = self.canvas.winfo_width()\n",
    "        self.current_parameters['canvas_height'] = self.canvas.winfo_height()\n",
    "        try:\n",
    "            # Safely handle eye positions\n",
    "            right_eye_pos = eval(self.current_parameters['right_eye_position']\n",
    "                                 ) if self.current_parameters['right_eye_position'] != 'None' else (None, None)\n",
    "            left_eye_pos = eval(self.current_parameters['left_eye_position']\n",
    "                                ) if self.current_parameters['left_eye_position'] != 'None' else (None, None)\n",
    "\n",
    "            # Safely handle face and eye positions - make sure to handle None case\n",
    "            right_eye_box = self.current_parameters.get('right_eye_bbox')\n",
    "            if right_eye_box is None or right_eye_box == 'None':\n",
    "                right_eye_box = [None, None, None, None]\n",
    "\n",
    "            left_eye_box = self.current_parameters.get('left_eye_bbox')\n",
    "            if left_eye_box is None or left_eye_box == 'None':\n",
    "                left_eye_box = [None, None, None, None]\n",
    "\n",
    "            face_min_position = self.current_parameters.get(\n",
    "                'face_min_position')\n",
    "            if face_min_position is None or face_min_position == 'None':\n",
    "                face_min_position = [None, None]\n",
    "\n",
    "            face_max_position = self.current_parameters.get(\n",
    "                'face_max_position')\n",
    "            if face_max_position is None or face_max_position == 'None':\n",
    "                face_max_position = [None, None]\n",
    "\n",
    "            face_center_position = self.current_parameters.get(\n",
    "                'face_center_position')\n",
    "            if face_center_position is None or face_center_position == 'None':\n",
    "                face_center_position = [None, None]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing positions: {e}\")\n",
    "            right_eye_pos = [None, None]\n",
    "            left_eye_pos = [None, None]\n",
    "            right_eye_box = [None, None, None, None]\n",
    "            left_eye_box = [None, None, None, None]\n",
    "            face_min_position = [None, None]\n",
    "            face_max_position = [None, None]\n",
    "            face_center_position = [None, None]\n",
    "\n",
    "        # Prepare data for CSV with safe value extraction\n",
    "        data = {\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'file_number': filename_base,\n",
    "            # Resolution information\n",
    "            'screen_resolution_width': self.current_parameters.get('screen_resolution_width', 'N/A'),\n",
    "            'screen_resolution_height': self.current_parameters.get('screen_resolution_height', 'N/A'),\n",
    "            'webcam_resolution_width': self.current_parameters.get('webcam_resolution_width', 'N/A'),\n",
    "            'webcam_resolution_height': self.current_parameters.get('webcam_resolution_height', 'N/A'),\n",
    "            'preview_width': self.current_parameters.get('preview_width', 'N/A'),\n",
    "            'preview_height': self.current_parameters.get('preview_height', 'N/A'),\n",
    "            'canvas_width': self.current_parameters.get('canvas_width', 'N/A'),\n",
    "            'canvas_height': self.current_parameters.get('canvas_height', 'N/A'),\n",
    "            'gaze_direction': self.current_parameters.get('gaze_direction', 'N/A'),\n",
    "            'posture': self.current_parameters.get('posture', 'N/A'),\n",
    "            'dot_position_x': self.current_parameters.get('dot_position_x', 'N/A'),\n",
    "            'dot_position_y': self.current_parameters.get('dot_position_y', 'N/A'),\n",
    "            'distance_cm': self.current_parameters.get('distance', 'N/A'),\n",
    "            # face\n",
    "            'face_size_width': self.current_parameters.get('face_size_width', 'N/A'),\n",
    "            'face_size_hight': self.current_parameters.get('face_size_hight', 'N/A'),\n",
    "            'face_min_position_x': 'N/A' if face_min_position[0] is None else face_min_position[0],\n",
    "            'face_min_position_y': 'N/A' if face_min_position[1] is None else face_min_position[1],\n",
    "            'face_max_position_x': 'N/A' if face_max_position[0] is None else face_max_position[0],\n",
    "            'face_max_position_y': 'N/A' if face_max_position[1] is None else face_max_position[1],\n",
    "            'face_center_position_x': 'N/A' if face_center_position[0] is None else face_center_position[0],\n",
    "            'face_center_position_y': 'N/A' if face_center_position[1] is None else face_center_position[1],\n",
    "            # eye Pupil\n",
    "            'left_eye_pupil_x': 'N/A' if left_eye_pos[0] is None else left_eye_pos[0],\n",
    "            'left_eye_pupil_y': 'N/A' if left_eye_pos[1] is None else left_eye_pos[1],\n",
    "            'right_eye_pupil_x': 'N/A' if right_eye_pos[0] is None else right_eye_pos[0],\n",
    "            'right_eye_pupil_y': 'N/A' if right_eye_pos[1] is None else right_eye_pos[1],\n",
    "            # eye box\n",
    "            'right_eye_bbox_min_x': 'N/A' if right_eye_box[0] is None else right_eye_box[0],\n",
    "            'right_eye_bbox_min_y': 'N/A' if right_eye_box[1] is None else right_eye_box[1],\n",
    "            'right_eye_bbox_max_x': 'N/A' if right_eye_box[2] is None else right_eye_box[2],\n",
    "            'right_eye_bbox_max_y': 'N/A' if right_eye_box[3] is None else right_eye_box[3],\n",
    "            'left_eye_bbox_min_x': 'N/A' if left_eye_box[0] is None else left_eye_box[0],\n",
    "            'left_eye_bbox_min_y': 'N/A' if left_eye_box[1] is None else left_eye_box[1],\n",
    "            'left_eye_bbox_max_x': 'N/A' if left_eye_box[2] is None else left_eye_box[2],\n",
    "            'left_eye_bbox_max_y': 'N/A' if left_eye_box[3] is None else left_eye_box[3],\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(csv_path, 'w', newline='') as f:\n",
    "                for key, value in data.items():\n",
    "                    if value is None:\n",
    "                        value = \"N/A\"\n",
    "                    f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "            print(f\"Successfully saved parameters to {csv_path}\")\n",
    "\n",
    "            # Debug print to verify data\n",
    "            print(\"\\nSaved parameters:\")\n",
    "            for key, value in data.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving parameters: {e}\")\n",
    "\n",
    "    def update_dot_label_position(self):\n",
    "        # Get label dimensions\n",
    "        label_width = self.dot_countdown_label.winfo_reqwidth()\n",
    "        label_height = self.dot_countdown_label.winfo_reqheight()\n",
    "\n",
    "        # Get screen/canvas bounds\n",
    "        canvas_width = self.canvas.winfo_width()\n",
    "        canvas_height = self.canvas.winfo_height()\n",
    "\n",
    "        # Default position (centered above dot)\n",
    "        x = self.dot_x - label_width//2\n",
    "        y = self.dot_y - 50\n",
    "\n",
    "        # Check horizontal bounds\n",
    "        if x < 0:  # Too far left\n",
    "            x = self.dot_x + 20  # Place to right of dot\n",
    "        elif x + label_width > canvas_width:  # Too far right\n",
    "            x = self.dot_x - label_width - 20  # Place to left of dot\n",
    "\n",
    "        # Check vertical bounds\n",
    "        if y < 0:  # Too high\n",
    "            y = self.dot_y + 20  # Place below dot\n",
    "        elif y + label_height > canvas_height:  # Too low\n",
    "            y = self.dot_y - label_height - 20  # Place above dot\n",
    "\n",
    "        # Handle corner cases\n",
    "        if x < 0 and y < 0:  # Top-left corner\n",
    "            x = self.dot_x + 20\n",
    "            y = self.dot_y + 20\n",
    "        elif x + label_width > canvas_width and y < 0:  # Top-right corner\n",
    "            x = self.dot_x - label_width - 20\n",
    "            y = self.dot_y + 20\n",
    "        elif x < 0 and y + label_height > canvas_height:  # Bottom-left corner\n",
    "            x = self.dot_x + 20\n",
    "            y = self.dot_y - label_height - 20\n",
    "        elif x + label_width > canvas_width and y + label_height > canvas_height:  # Bottom-right corner\n",
    "            x = self.dot_x - label_width - 20\n",
    "            y = self.dot_y - label_height - 20\n",
    "        return x, y\n",
    "\n",
    "    def countdown(self, count):\n",
    "        if count > 0:\n",
    "            countdown_text = str(count)\n",
    "            self.countdown_label.config(text=countdown_text)\n",
    "            self.dot_countdown_label.config(text=countdown_text)\n",
    "            self.dot_countdown_label.update_idletasks()  # This is important!\n",
    "            x_label, y_label = self.update_dot_label_position()\n",
    "            # Place label above dot\n",
    "            self.dot_countdown_label.place(\n",
    "                x=x_label,\n",
    "                y=y_label\n",
    "            )\n",
    "            self.dot_countdown_label.lift()\n",
    "            # self.random_button.config(state=tk.DISABLED)\n",
    "            self.root.after(1000, lambda: self.countdown(count - 1))\n",
    "        else:\n",
    "            self.countdown_label.config(text=\"Capturing...\")\n",
    "            self.dot_countdown_label.place_forget()\n",
    "\n",
    "            # self.random_button.config(state=tk.NORMAL)\n",
    "            self.root.after(500, self.capture_sequence)\n",
    "\n",
    "    def update_next_available_number(self):\n",
    "        \"\"\"Find the next available file number by checking existing files\"\"\"\n",
    "        while True:\n",
    "            webcam_file = os.path.join(\n",
    "                self.output_dir,\n",
    "                f\"webcam_{self.file_counter:03d}.jpg\"\n",
    "            )\n",
    "            screen_file = os.path.join(\n",
    "                self.output_dir,\n",
    "                f\"screen_{self.file_counter:03d}.jpg\"\n",
    "            )\n",
    "\n",
    "            if not os.path.exists(webcam_file) and not os.path.exists(screen_file):\n",
    "                break\n",
    "            self.file_counter += 1\n",
    "\n",
    "    def capture_sequence(self):\n",
    "        # Generate filename with current counter\n",
    "        try:\n",
    "            self.switch_parameterOnScreen = False\n",
    "            filename_base = f\"{self.file_counter:03d}\"\n",
    "            webcam_path = os.path.join(\n",
    "                self.output_dir, f\"webcam_{filename_base}.jpg\")\n",
    "            screen_path = os.path.join(\n",
    "                self.output_dir, f\"screen_{filename_base}.jpg\")\n",
    "\n",
    "            # Remove this condition since we want preview to show always\n",
    "            # if not self.preview_var.get():\n",
    "            #     self.preview_var.set(True)\n",
    "            #     self.toggle_preview()\n",
    "\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                try:\n",
    "                    # Process webcam frame\n",
    "                    frame_processed = self.process_frame(frame.copy())\n",
    "\n",
    "                    # selected_idx = self.screen_dropdown.current()\n",
    "                    # if selected_idx >= 0 and selected_idx < len(self.screens):\n",
    "                    #     selected_monitor = self.screens[selected_idx]\n",
    "                    #     # Capture specific screen\n",
    "                    #     screen = pyautogui.screenshot(\n",
    "                    #         region=(\n",
    "                    #             selected_monitor.x,\n",
    "                    #             selected_monitor.y,\n",
    "                    #             selected_monitor.width,\n",
    "                    #             selected_monitor.height\n",
    "                    #         )\n",
    "                    #     )\n",
    "                    # else:\n",
    "                    #     # Fallback to full screenshot if no screen selected\n",
    "                    #     screen = pyautogui.screenshot()\n",
    "                    # screen = pyautogui.screenshot()\n",
    "\n",
    "                    canvas_x = self.canvas.winfo_rootx()\n",
    "                    canvas_y = self.canvas.winfo_rooty()\n",
    "                    canvas_width = self.canvas.winfo_width()\n",
    "                    canvas_height = self.canvas.winfo_height()\n",
    "\n",
    "                    # Capture only the canvas area\n",
    "                    canvas_screenshot = pyautogui.screenshot(\n",
    "                        region=(\n",
    "                            canvas_x,\n",
    "                            canvas_y,\n",
    "                            canvas_width,\n",
    "                            canvas_height\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    screen_np = np.array(canvas_screenshot)\n",
    "                    screen_bgr = cv2.cvtColor(screen_np, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(screen_path, screen_bgr)\n",
    "                    cv2.imwrite(webcam_path, frame_processed)\n",
    "\n",
    "                    self.save_parameters_to_csv(filename_base)\n",
    "\n",
    "                    # Update preview displays\n",
    "                    frame_rgb = cv2.cvtColor(\n",
    "                        frame_processed, cv2.COLOR_BGR2RGB)\n",
    "                    frame_resized = cv2.resize(\n",
    "                        frame_rgb, (self.webcam_width, self.webcam_height))\n",
    "                    screen_resized = cv2.resize(\n",
    "                        screen_np, (self.webcam_width, self.webcam_height))\n",
    "\n",
    "                    webcam_pil = Image.fromarray(frame_resized)\n",
    "                    screen_pil = Image.fromarray(screen_resized)\n",
    "\n",
    "                    photo = ImageTk.PhotoImage(image=webcam_pil)\n",
    "                    screen_photo = ImageTk.PhotoImage(image=screen_pil)\n",
    "\n",
    "                    self.webcam_label.configure(image=photo)\n",
    "                    self.webcam_label.image = photo\n",
    "                    self.screen_label.configure(image=screen_photo)\n",
    "                    self.screen_label.image = screen_photo\n",
    "\n",
    "                    print(f\"Images saved successfully:\")\n",
    "                    print(f\"- Webcam: {webcam_path}\")\n",
    "                    print(f\"- Canvas: {screen_path}\")\n",
    "\n",
    "                    # Increment counter for next capture\n",
    "                    self.file_counter += 1\n",
    "                    self.update_next_available_number()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during capture: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "\n",
    "                # Always show preview after capture\n",
    "                self.canvas_normal_state = False\n",
    "                self.canvas.configure(\n",
    "                    width=self.original_canvas_width,\n",
    "                    height=self.original_canvas_height * 0.7\n",
    "                )\n",
    "                self.preview_frame.place(\n",
    "                    in_=self.canvas_frame,\n",
    "                    # relx=0.2,\n",
    "                    # rely=0.5,\n",
    "                    # anchor='left'\n",
    "                )\n",
    "                self.preview_frame.configure(bg='white')\n",
    "                self.webcam_label.pack(side=tk.LEFT, padx=5)\n",
    "                self.screen_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "                # Hide preview after 2 seconds\n",
    "                self.root.after(\n",
    "                    2000, lambda: self.hide_preview_after_capture(True))\n",
    "\n",
    "            # Reset UI state\n",
    "            self.countdown_label.config(text=\"\")\n",
    "            self.random_button.config(state=tk.NORMAL)\n",
    "        finally:\n",
    "            # Always reset the capture flag when done\n",
    "            self.capture_in_progress = False\n",
    "\n",
    "        return self.capture_in_progress\n",
    "\n",
    "    def hide_preview_after_capture(self, was_hidden):\n",
    "        if was_hidden:\n",
    "            self.canvas_normal_state = True\n",
    "            self.webcam_label.pack_forget()\n",
    "            self.screen_label.pack_forget()\n",
    "            self.preview_frame.place_forget()\n",
    "            self.toggle_controls(force_hide=False)\n",
    "\n",
    "            self.canvas.configure(\n",
    "                width=self.original_canvas_width,\n",
    "                height=self.original_canvas_height\n",
    "            )\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.current_dot = None\n",
    "        self.screen_label.configure(image='')\n",
    "        self.countdown_label.config(text=\"\")\n",
    "        self.dot_countdown_label.place_forget()\n",
    "        self.distance_label.config(text=\"Distance: -- cm\")\n",
    "        self.posture_label.config(text=\"Posture: --\")\n",
    "\n",
    "        # Ensure random button is enabled\n",
    "        self.random_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = YoloDistanceApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[10054]: Class CaptureDelegate is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17dc1e520) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x137970860). One of the two will be used. Which one is undefined.\n",
      "objc[10054]: Class CVWindow is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17dc1e570) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x120dd4a68). One of the two will be used. Which one is undefined.\n",
      "objc[10054]: Class CVView is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17dc1e598) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x120dd4a90). One of the two will be used. Which one is undefined.\n",
      "objc[10054]: Class CVSlider is implemented in both /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x17dc1e5c0) and /Users/porchportal2/miniforge3/envs/Video_captioning/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x120dd4ab8). One of the two will be used. Which one is undefined.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: out device of bound (0-0): 1\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(\n",
    "    color=(128, 0, 128), thickness=2, circle_radius=1)\n",
    "\n",
    "\n",
    "def draw_pose_vectors(image, p1, angles, size=100):\n",
    "    \"\"\"Draw 3D pose vectors with RGB colors for each axis with enhanced movement\"\"\"\n",
    "    x, y, z = angles\n",
    "\n",
    "    # Add offset correction to improve accuracy\n",
    "    x_offset = -4  # Adjust these offset values as needed\n",
    "\n",
    "    # Calculate angles with offset correction\n",
    "    pitch = -(x + x_offset) * np.pi / 90\n",
    "    yaw = y * np.pi / 90\n",
    "    roll = z * np.pi / 90\n",
    "\n",
    "    # Calculate rotation matrices\n",
    "    Rz = np.array([[np.cos(roll), -np.sin(roll), 0],\n",
    "                   [np.sin(roll), np.cos(roll), 0],\n",
    "                   [0, 0, 1]])\n",
    "\n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, np.cos(pitch), -np.sin(pitch)],\n",
    "                   [0, np.sin(pitch), np.cos(pitch)]])\n",
    "\n",
    "    Ry = np.array([[np.cos(yaw), 0, np.sin(yaw)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(yaw), 0, np.cos(yaw)]])\n",
    "\n",
    "    # Combine rotations\n",
    "    R = Rz @ Ry @ Rx\n",
    "\n",
    "    # Initial vectors\n",
    "    v1 = np.array([size * 1.5, 0, 0])    # X axis, made longer\n",
    "    v2 = np.array([0, -size * 1.5, 0])   # Y axis, made longer\n",
    "    v3 = np.array([0, 0, -size * 1.5])\n",
    "\n",
    "    # Rotate vectors\n",
    "    v1_rotated = R @ v1\n",
    "    v2_rotated = R @ v2\n",
    "    v3_rotated = R @ v3\n",
    "\n",
    "    # Project to 2D and draw\n",
    "    # X axis - Red\n",
    "    p2 = (int(p1[0] + v1_rotated[0]), int(p1[1] + v1_rotated[1]))\n",
    "    cv2.line(image, p1, p2, (0, 0, 255), 4)\n",
    "\n",
    "    # Y axis - Green\n",
    "    p2 = (int(p1[0] + v2_rotated[0]), int(p1[1] + v2_rotated[1]))\n",
    "    cv2.line(image, p1, p2, (0, 255, 0), 4)\n",
    "\n",
    "    # Z axis - Blue\n",
    "    p2 = (int(p1[0] + v3_rotated[0]), int(p1[1] + v3_rotated[1]))\n",
    "    cv2.line(image, p1, p2, (255, 0, 0), 4)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_2d = []\n",
    "    face_3d = []\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                    face_2d.append([x, y])\n",
    "                    face_3d.append([x, y, lm.z])\n",
    "\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            focal_length = 1 * img_w\n",
    "            cam_matrix = np.array([\n",
    "                [focal_length, 0, img_h/2],\n",
    "                [0, focal_length, img_w/2],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "            distortion_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            success, rotation_vec, translation_vec = cv2.solvePnP(\n",
    "                face_3d, face_2d, cam_matrix, distortion_matrix)\n",
    "\n",
    "            rmat, jac = cv2.Rodrigues(rotation_vec)\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "            z = angles[2] * 360\n",
    "\n",
    "            # Draw pose vectors on the left side\n",
    "            positionOfVector_visualization = (150, 300)\n",
    "\n",
    "            # Amplify the angles for more visible movement\n",
    "            speed_up = 3.5\n",
    "            amplified_angles = (x * speed_up, y * speed_up, z * speed_up)\n",
    "            draw_pose_vectors(\n",
    "                image, positionOfVector_visualization, amplified_angles)\n",
    "\n",
    "            # Text for angles\n",
    "            cv2.putText(image, \"x: \" + str(np.round(x, 2)), (500, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"y: \" + str(np.round(y, 2)), (500, 100),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"z: \" + str(np.round(z, 2)), (500, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            x_angle = np.arctan2(Qx[2][1], Qx[2][2])\n",
    "            y_angle = np.arctan2(-Qy[2][0], np.sqrt((Qy[2]\n",
    "                                 [1] * Qy[2][1]) + (Qy[2][2] * Qy[2][2])))\n",
    "            z_angle = np.arctan2(Qz[0][0], Qz[1][0])\n",
    "\n",
    "            cv2.putText(image, \"x_angle: \" + str(np.round(x_angle, 5)), (500, 200),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"y_angle: \" + str(np.round(y_angle, 5)), (500, 250),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"z_angle: \" + str(np.round(z_angle, 5)), (500, 300),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # print(\"\\nCalculated angles (radians):\")\n",
    "            # print(f\"x_angle: {x_angle:.4f}\")\n",
    "            # print(f\"y_angle: {y_angle:.4f}\")\n",
    "            # print(f\"z_angle: {z_angle:.4f}\")\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=drawing_spec,\n",
    "                connection_drawing_spec=drawing_spec)\n",
    "\n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "        fps = 1 / totalTime\n",
    "        cv2.putText(image, f'FPS: {int(fps)}', (20, 450),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Head Pose Detection', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 11:04:11.330 python[10054:795396] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-24 11:04:11.330 python[10054:795396] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Update gaze tracking\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[43mgaze\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# YOLO face detection with improved parameters\u001b[39;00m\n\u001b[1;32m     70\u001b[0m results \u001b[38;5;241m=\u001b[39m model_face\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m     71\u001b[0m     frame,\n\u001b[1;32m     72\u001b[0m     conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,          \u001b[38;5;66;03m# Lower confidence threshold\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     77\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/🔥everything/Video_captioning/file/program/CaptureEye&Screen/gaze_tracking/gaze_tracking.py:63\u001b[0m, in \u001b[0;36mGazeTracking.refresh\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Refreshes the frame and analyzes it.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    frame (numpy.ndarray): The frame to analyze\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/🔥everything/Video_captioning/file/program/CaptureEye&Screen/gaze_tracking/gaze_tracking.py:45\u001b[0m, in \u001b[0;36mGazeTracking._analyze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Detects the face and initialize Eye objects\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m---> 45\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_face_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     landmarks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor(frame, faces[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gaze_tracking import GazeTracking\n",
    "\n",
    "# Initialize all trackers\n",
    "gaze = GazeTracking()\n",
    "# Download the updated model\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
    "# Initialize YOLO with specific parameters\n",
    "model_face = YOLO(model_path)\n",
    "model_face.conf = 0.25  # Lower confidence threshold for detection\n",
    "model_face.iou = 0.45   # IOU threshold for NMS\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "fm = FaceMeshDetector(maxFaces=1)  # Limit to one face for better accuracy\n",
    "\n",
    "# Define eye landmark points as dictionaries\n",
    "rightEye = {\n",
    "    'upper': [463, 414, 286, 258, 257, 259, 260],\n",
    "    'lower': [467, 359, 255, 339, 254, 253, 252, 256, 341]\n",
    "}\n",
    "\n",
    "leftEye = {\n",
    "    'upper': [130, 247, 30, 29, 27, 28, 56],\n",
    "    'lower': [190, 243, 112, 26, 22, 23, 24, 110, 25]\n",
    "}\n",
    "\n",
    "# Initialize parameters\n",
    "focal_length = 1000\n",
    "known_distance = 70\n",
    "known_width = 14\n",
    "switch_ShowParameter = True\n",
    "\n",
    "\n",
    "def get_eye_bbox(landmarks, eye_points):\n",
    "    point_array = np.array([landmarks[idx]\n",
    "                           for group in eye_points.values() for idx in group])\n",
    "    x_min = int(np.min(point_array[:, 0])) - 10\n",
    "    x_max = int(np.max(point_array[:, 0])) + 10\n",
    "    y_min = int(np.min(point_array[:, 1])) - 10\n",
    "    y_max = int(np.max(point_array[:, 1])) + 10\n",
    "    return (x_min, y_min), (x_max, y_max)\n",
    "\n",
    "\n",
    "def measure_distance(face_width_pixels):\n",
    "    return (known_width * focal_length) / face_width_pixels\n",
    "\n",
    "\n",
    "def draw_position_text(frame, text, y_pos, color=(255, 255, 255)):\n",
    "    \"\"\"Draw single line of position text\"\"\"\n",
    "    cv.putText(frame, text, (10, y_pos),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 1.4, color, 3)\n",
    "    return y_pos + 54\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Update gaze tracking\n",
    "    gaze.refresh(frame)\n",
    "\n",
    "    # YOLO face detection with improved parameters\n",
    "    results = model_face.predict(\n",
    "        frame,\n",
    "        conf=0.25,          # Lower confidence threshold\n",
    "        iou=0.45,           # IOU threshold\n",
    "        max_det=1,          # Maximum number of detections\n",
    "        classes=[0],        # Only detect faces\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Face mesh detection\n",
    "    frame_mesh, faces = fm.findFaceMesh(frame, draw=0)\n",
    "\n",
    "    # Check if any faces were detected by both YOLO and face mesh\n",
    "    if len(results[0].boxes) > 0:\n",
    "        box = results[0].boxes[0]\n",
    "        conf = float(box.conf[0])\n",
    "\n",
    "        # Only process if confidence is good enough\n",
    "        if conf >= 0.25:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            # Calculate face measurements\n",
    "            face_width = x2 - x1\n",
    "            face_height = y2 - y1\n",
    "            face_center_x = (x1 + x2) // 2\n",
    "            face_center_y = (y1 + y2) // 2\n",
    "\n",
    "            # Calculate distance\n",
    "            distance = measure_distance(face_width)\n",
    "\n",
    "            if switch_ShowParameter:\n",
    "                frame = gaze.annotated_frame()\n",
    "                y_position = 40\n",
    "\n",
    "                # Debug info for YOLO detection\n",
    "                cv.putText(frame, f\"YOLO Confidence: {conf:.3f}\", (10, y_position),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                y_position += 54\n",
    "\n",
    "                cv.putText(frame, f\"Face Size: {round(face_width, 2)} x {round(face_height, 2)}\",\n",
    "                           (10, y_position), cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                y_position += 54\n",
    "\n",
    "                # Draw pupil positions\n",
    "                right_pupil = gaze.pupil_right_coords()\n",
    "                left_pupil = gaze.pupil_left_coords()\n",
    "                if right_pupil:\n",
    "                    cv.putText(frame, f\"Right Pupil: {right_pupil}\", (10, y_position),\n",
    "                               cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                    y_position += 54\n",
    "                if left_pupil:\n",
    "                    cv.putText(frame, f\"Left Pupil: {left_pupil}\", (10, y_position),\n",
    "                               cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                    y_position += 54\n",
    "\n",
    "                # Draw face box and position\n",
    "                cv.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv.putText(frame, f\"Face -> min:({x1} ,{y1}), max:({x2} ,{y2})\", (10, y_position),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                y_position += 54\n",
    "\n",
    "                # Draw face center\n",
    "                cv.circle(frame, (face_center_x, face_center_y),\n",
    "                          3, (0, 255, 0), -1)\n",
    "                cv.putText(frame, f\"Face Center: ({face_center_x} ,{face_center_y})\",\n",
    "                           (10, y_position), cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                y_position += 54\n",
    "\n",
    "                # Process eye landmarks if face mesh is detected\n",
    "                if faces:\n",
    "                    face_landmarks = faces[0]\n",
    "                    for eye_name, eye_points in [(\"Right Eye\", rightEye), (\"Left Eye\", leftEye)]:\n",
    "                        (ex1, ey1), (ex2, ey2) = get_eye_bbox(\n",
    "                            face_landmarks, eye_points)\n",
    "                        cv.rectangle(frame, (ex1, ey1),\n",
    "                                     (ex2, ey2), (0, 255, 0), 2)\n",
    "                        cv.putText(frame, f\"{eye_name}-> min:({ex1} ,{ey1}), max:({ex2} ,{ey2})\", (10, y_position),\n",
    "                                   cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                        y_position += 54\n",
    "                        # Draw eye landmarks\n",
    "                        for i in eye_points['upper']:\n",
    "                            cv.circle(\n",
    "                                frame, face_landmarks[i], 2, (0, 255, 255), -1)\n",
    "                        for i in eye_points['lower']:\n",
    "                            cv.circle(\n",
    "                                frame, face_landmarks[i], 2, (255, 255, 0), -1)\n",
    "                # Draw measurements\n",
    "                cv.putText(frame, f\"Distance: {distance:.1f} cm\",\n",
    "                           (10, y_position), cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "                y_position += 54\n",
    "\n",
    "                # Draw gaze direction\n",
    "                if gaze.is_right():\n",
    "                    gaze_text = \"Looking right\"\n",
    "                elif gaze.is_left():\n",
    "                    gaze_text = \"Looking left\"\n",
    "                elif gaze.is_center():\n",
    "                    gaze_text = \"Looking center\"\n",
    "                else:\n",
    "                    gaze_text = \"Gaze not detected\"\n",
    "                cv.putText(frame, f\"Gaze: {gaze_text}\", (10, y_position),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)\n",
    "\n",
    "    # Display the frame\n",
    "    cv.imshow(\"Demo\", frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Video_captioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
